{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1097cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5115a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12bfa4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['english_1','filipino','chinese','korean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10254e93",
   "metadata": {},
   "source": [
    "### Save All Tradition models in Output Folder in Joblib Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc418f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filipino_SVM_char.joblib',\n",
       " 'korean_RF_char.joblib',\n",
       " 'chinese_SVM_word.joblib',\n",
       " '.DS_Store',\n",
       " 'english_1_GBT_word.joblib',\n",
       " 'korean_GBT_char.joblib',\n",
       " 'english_1_RF_word.joblib',\n",
       " 'filipino_NB_char.joblib',\n",
       " 'chinese_NB_word.joblib',\n",
       " 'filipino_LR_word.joblib',\n",
       " 'chinese_LR_char.joblib',\n",
       " 'korean_NB_char.joblib',\n",
       " 'korean_LR_word.joblib',\n",
       " 'chinese_GBT_char.joblib',\n",
       " 'filipino_GBT_word.joblib',\n",
       " 'english_1_NB_word.joblib',\n",
       " 'chinese_RF_word.joblib',\n",
       " 'filipino_RF_char.joblib',\n",
       " 'english_1_SVM_char.joblib',\n",
       " 'korean_SVM_word.joblib',\n",
       " 'english_1_LR_char.joblib',\n",
       " 'chinese_LR_word.joblib',\n",
       " 'filipino_LR_char.joblib',\n",
       " 'english_1_RF_char.joblib',\n",
       " 'chinese_NB_char.joblib',\n",
       " 'filipino_NB_word.joblib',\n",
       " 'english_1_GBT_char.joblib',\n",
       " 'korean_GBT_word.joblib',\n",
       " 'chinese_SVM_char.joblib',\n",
       " 'filipino_SVM_word.joblib',\n",
       " 'korean_RF_word.joblib',\n",
       " 'english_1_LR_word.joblib',\n",
       " 'english_1_SVM_word.joblib',\n",
       " 'english_1_NB_char.joblib',\n",
       " 'filipino_RF_word.joblib',\n",
       " 'chinese_RF_char.joblib',\n",
       " 'korean_SVM_char.joblib',\n",
       " 'filipino_GBT_char.joblib',\n",
       " 'chinese_GBT_word.joblib',\n",
       " 'korean_LR_char.joblib',\n",
       " 'korean_NB_word.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ad5c2",
   "metadata": {},
   "source": [
    "### Save all CNN Models in temp as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28a163bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english_1_model_char',\n",
       " 'korean_model_word',\n",
       " 'filipino_model_char',\n",
       " '.DS_Store',\n",
       " 'chinese_model_char',\n",
       " 'chinese_model_hybrid',\n",
       " 'korean_model_GLOVE_word',\n",
       " 'english_1_model_GLOVE_word',\n",
       " 'chinese_model_GLOVE_word',\n",
       " 'filipino_model_hybrid',\n",
       " 'korean_model_GLOVE_hybrid',\n",
       " 'korean_model_hybrid',\n",
       " 'chinese_model_GLOVE_hybrid',\n",
       " 'english_1_model_word',\n",
       " 'korean_model_char',\n",
       " 'english_1_model_GLOVE_hybrid',\n",
       " 'korean_model_GLOVE_char',\n",
       " 'english_1_model_GLOVE_char',\n",
       " 'filipino_model_word',\n",
       " 'chinese_model_word',\n",
       " 'chinese_model_GLOVE_char',\n",
       " 'english_1_model_hybrid']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('temp/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56167c95",
   "metadata": {},
   "source": [
    "### Save Embeddings in temp folder of this notebook as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef947afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['korean',\n",
       " '.DS_Store',\n",
       " 'english_1',\n",
       " 'english_1_glove',\n",
       " 'chinese',\n",
       " 'filipino',\n",
       " 'chinese_glove',\n",
       " 'korean_glove']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('temp/embeds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc686b0",
   "metadata": {},
   "source": [
    "# All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4da0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vector2matrix(text_vector, max_len=140, N_DIM=70):\n",
    "\tmatrix = np.zeros((max_len, N_DIM))\n",
    "\tfor i, index_elem in enumerate(text_vector):\n",
    "\t\trow = np.zeros(N_DIM)\n",
    "\t\tif int(index_elem) != -1:\n",
    "\t\t\trow[int(index_elem)] = 1\n",
    "\t\tmatrix[i] = row\n",
    "\treturn matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e627619",
   "metadata": {},
   "source": [
    "## Maximize Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e502a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c629ebcf3374f3387baeb6f8fc95cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2294d9efeb9741e3930440b667ca2701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 19:06:00.739228: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-02 19:06:00.742210: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.93      0.36      0.52      4124\n",
      "not_offensive       0.21      0.86      0.34       833\n",
      "\n",
      "     accuracy                           0.45      4957\n",
      "    macro avg       0.57      0.61      0.43      4957\n",
      " weighted avg       0.81      0.45      0.49      4957\n",
      "\n",
      "filipino\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3375f2ea104c3eb71238fc3a814a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fd9def64914532a2a1f825a4dc7ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.52      0.52      0.52      2251\n",
      "not_offensive       0.58      0.58      0.58      2596\n",
      "\n",
      "     accuracy                           0.55      4847\n",
      "    macro avg       0.55      0.55      0.55      4847\n",
      " weighted avg       0.55      0.55      0.55      4847\n",
      "\n",
      "chinese\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619aecce99d1482683e6d730a9902a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ba6019d2c04a5ebe032315a0fb429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.35      0.68      0.46       619\n",
      "not_offensive       0.66      0.33      0.44      1175\n",
      "\n",
      "     accuracy                           0.45      1794\n",
      "    macro avg       0.50      0.50      0.45      1794\n",
      " weighted avg       0.55      0.45      0.45      1794\n",
      "\n",
      "korean\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bf7660d3af458d8e7d638d465683b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4169d4fa014672ab6e3cb5380df833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive       0.45      0.54      0.49       697\n",
      "    offensive       0.58      0.50      0.54       903\n",
      "\n",
      "     accuracy                           0.52      1600\n",
      "    macro avg       0.52      0.52      0.52      1600\n",
      " weighted avg       0.53      0.52      0.52      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    print(lang)\n",
    "    models = [i for i in os.listdir('output') if lang in i]\n",
    "    proc_data = pickle.load(open(f'processed_data/{lang}_processed.pkl','rb'))\n",
    "    preds = []\n",
    "    for m in tqdm(models):\n",
    "        loaded_model = joblib.load(f'output/{m}')\n",
    "        preds.append(loaded_model[0].predict_proba(proc_data['text_test']))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X_word = np.load(f'temp/embeds/{lang}/CtxtText_InputText_test.npy')[:,100:]\n",
    "    # X_char = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    char_text_data_list = []\n",
    "    _char_text_data = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    for text_vector in _char_text_data:\n",
    "        char_text_data_list.append(vector2matrix(text_vector))\n",
    "    char_text_data = np.asarray(char_text_data_list)\n",
    "    X_char = char_text_data\n",
    "\n",
    "#     preds = []\n",
    "\n",
    "    for cnn_model in tqdm([i for i in os.listdir('temp/models') if lang in i]):\n",
    "        model = keras.models.load_model(f'temp/models/{cnn_model}')\n",
    "        if 'char' in cnn_model:\n",
    "            preds.append(model.predict(X_char,batch_size=128))\n",
    "        elif 'word' in cnn_model:\n",
    "            preds.append(model.predict(X_word,batch_size=128))\n",
    "        else:\n",
    "            preds.append(model.predict([X_word,X_char],batch_size=128))\n",
    "\n",
    "        \n",
    "    ans = []\n",
    "    for i in range(len(preds[0])):\n",
    "        ts = []\n",
    "        for j in range(len(preds)):\n",
    "            ts = ts + list(preds[j][i])\n",
    "        ans.append(ts.index(max(ts))%2)\n",
    "    test_label_data = [i.tolist().index(1) for i in proc_data['label_test']]\n",
    "    print(classification_report(test_label_data, ans,target_names=list(proc_data['label_dict'].keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c5495",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75821de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00b7c7571b24992a767cd52a01e5a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1a370bf4c340cea64ef9a1bc343bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.96      0.97      0.96      4124\n",
      "not_offensive       0.85      0.78      0.81       833\n",
      "\n",
      "     accuracy                           0.94      4957\n",
      "    macro avg       0.90      0.88      0.89      4957\n",
      " weighted avg       0.94      0.94      0.94      4957\n",
      "\n",
      "filipino\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e679f8c509a546c18ebd78f1ee00e932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aac3fe634574fcd87e7bf9dae8b2a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.79      0.79      0.79      2251\n",
      "not_offensive       0.82      0.82      0.82      2596\n",
      "\n",
      "     accuracy                           0.81      4847\n",
      "    macro avg       0.81      0.81      0.81      4847\n",
      " weighted avg       0.81      0.81      0.81      4847\n",
      "\n",
      "chinese\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a70f4ac713414f95fc97c55da0f861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b0cf5e9fb24ce6afc03c336b38c65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.85      0.22      0.34       619\n",
      "not_offensive       0.70      0.98      0.82      1175\n",
      "\n",
      "     accuracy                           0.72      1794\n",
      "    macro avg       0.78      0.60      0.58      1794\n",
      " weighted avg       0.75      0.72      0.66      1794\n",
      "\n",
      "korean\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a911c9a10ca48d89be1d5ebb66437e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672c3c03bde74d5d824f0eac161f6528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive       0.80      0.41      0.54       697\n",
      "    offensive       0.67      0.92      0.77       903\n",
      "\n",
      "     accuracy                           0.70      1600\n",
      "    macro avg       0.73      0.66      0.66      1600\n",
      " weighted avg       0.73      0.70      0.67      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    print(lang)\n",
    "    models = [i for i in os.listdir('output') if lang in i]\n",
    "    proc_data = pickle.load(open(f'processed_data/{lang}_processed.pkl','rb'))\n",
    "    preds = []\n",
    "    for m in tqdm(models):\n",
    "        loaded_model = joblib.load(f'output/{m}')\n",
    "        preds.append(loaded_model[0].predict_proba(proc_data['text_test']))\n",
    "        \n",
    "        \n",
    "    X_word = np.load(f'temp/embeds/{lang}/CtxtText_InputText_test.npy')[:,100:]\n",
    "    # X_char = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    char_text_data_list = []\n",
    "    _char_text_data = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    for text_vector in _char_text_data:\n",
    "        char_text_data_list.append(vector2matrix(text_vector))\n",
    "    char_text_data = np.asarray(char_text_data_list)\n",
    "    X_char = char_text_data\n",
    "\n",
    "#     preds = []\n",
    "\n",
    "    for cnn_model in tqdm([i for i in os.listdir('temp/models') if lang in i]):\n",
    "        model = keras.models.load_model(f'temp/models/{cnn_model}')\n",
    "        if 'char' in cnn_model:\n",
    "            preds.append(model.predict(X_char,batch_size=128))\n",
    "        elif 'word' in cnn_model:\n",
    "            preds.append(model.predict(X_word,batch_size=128))\n",
    "        else:\n",
    "            preds.append(model.predict([X_word,X_char],batch_size=128))\n",
    "    if lang=='filipino':\n",
    "        level = 7\n",
    "    else:\n",
    "        level = 8\n",
    "    ans = []\n",
    "    for i in range(len(preds[0])):\n",
    "        ts = []\n",
    "        for j in range(len(preds)):\n",
    "            ts = ts + list([preds[j][i].argmax()])\n",
    "        ans.append(1 if np.count_nonzero(ts)>=level else 0)\n",
    "    test_label_data = [i.tolist().index(1) for i in proc_data['label_test']]\n",
    "    print(classification_report(test_label_data, ans,target_names=list(proc_data['label_dict'].keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a3a64",
   "metadata": {},
   "source": [
    "# Word Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2ace3",
   "metadata": {},
   "source": [
    "## Maximize Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63247a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3bcdcc2131473aa54c2ec96704322e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11157d21d9f4e28b14c8200ccc50c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.92      0.31      0.46      4124\n",
      "not_offensive       0.20      0.87      0.33       833\n",
      "\n",
      "     accuracy                           0.40      4957\n",
      "    macro avg       0.56      0.59      0.39      4957\n",
      " weighted avg       0.80      0.40      0.44      4957\n",
      "\n",
      "filipino\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bab4690cc142fdaa1f446f3f84f65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274e4f574083429780c33c573a879efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.56      0.49      0.53      2251\n",
      "not_offensive       0.60      0.67      0.63      2596\n",
      "\n",
      "     accuracy                           0.59      4847\n",
      "    macro avg       0.58      0.58      0.58      4847\n",
      " weighted avg       0.58      0.59      0.58      4847\n",
      "\n",
      "chinese\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9793cea7c7645aea9c0d411f23d00ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207b33b2213f4ec88c510cb24fd40191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.35      0.67      0.46       619\n",
      "not_offensive       0.66      0.33      0.44      1175\n",
      "\n",
      "     accuracy                           0.45      1794\n",
      "    macro avg       0.50      0.50      0.45      1794\n",
      " weighted avg       0.55      0.45      0.45      1794\n",
      "\n",
      "korean\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e2fed49b1e441ea9ec0f492dfb7443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8b8d239a96465dbefd3f2273aaf0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive       0.46      0.48      0.47       697\n",
      "    offensive       0.58      0.55      0.57       903\n",
      "\n",
      "     accuracy                           0.52      1600\n",
      "    macro avg       0.52      0.52      0.52      1600\n",
      " weighted avg       0.53      0.52      0.52      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    print(lang)\n",
    "    models = [i for i in os.listdir('output') if lang in i and 'word' in i]\n",
    "    proc_data = pickle.load(open(f'processed_data/{lang}_processed.pkl','rb'))\n",
    "    preds = []\n",
    "    for m in tqdm(models):\n",
    "        loaded_model = joblib.load(f'output/{m}')\n",
    "        preds.append(loaded_model[0].predict_proba(proc_data['text_test']))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X_word = np.load(f'temp/embeds/{lang}/CtxtText_InputText_test.npy')[:,100:]\n",
    "    # X_char = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    char_text_data_list = []\n",
    "    _char_text_data = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    for text_vector in _char_text_data:\n",
    "        char_text_data_list.append(vector2matrix(text_vector))\n",
    "    char_text_data = np.asarray(char_text_data_list)\n",
    "    X_char = char_text_data\n",
    "\n",
    "#     preds = []\n",
    "\n",
    "    for cnn_model in tqdm([i for i in os.listdir('temp/models') if lang in i and 'word' in i]):\n",
    "        model = keras.models.load_model(f'temp/models/{cnn_model}')\n",
    "        if 'char' in cnn_model:\n",
    "            preds.append(model.predict(X_char,batch_size=128))\n",
    "        elif 'word' in cnn_model:\n",
    "            preds.append(model.predict(X_word,batch_size=128))\n",
    "        else:\n",
    "            preds.append(model.predict([X_word,X_char],batch_size=128))\n",
    "\n",
    "        \n",
    "    ans = []\n",
    "    for i in range(len(preds[0])):\n",
    "        ts = []\n",
    "        for j in range(len(preds)):\n",
    "            ts = ts + list(preds[j][i])\n",
    "        ans.append(ts.index(max(ts))%2)\n",
    "    test_label_data = [i.tolist().index(1) for i in proc_data['label_test']]\n",
    "    print(classification_report(test_label_data, ans,target_names=list(proc_data['label_dict'].keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04f9a0",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82a76386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065968e2ac37411884e16e013ce57764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0823e26cda54473fbf820fedf3e8aeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.94      0.99      0.96      4124\n",
      "not_offensive       0.91      0.67      0.78       833\n",
      "\n",
      "     accuracy                           0.93      4957\n",
      "    macro avg       0.93      0.83      0.87      4957\n",
      " weighted avg       0.93      0.93      0.93      4957\n",
      "\n",
      "filipino\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05392547b26b417995b475f503867eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60dd3f06c9046d1993700c71f3c70be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.78      0.81      0.79      2251\n",
      "not_offensive       0.83      0.80      0.81      2596\n",
      "\n",
      "     accuracy                           0.80      4847\n",
      "    macro avg       0.80      0.81      0.80      4847\n",
      " weighted avg       0.81      0.80      0.80      4847\n",
      "\n",
      "chinese\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ed2afc9c3c4ca3abeff5955e335bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d934cc695da4c4391f558a412eaca88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.68      0.03      0.06       619\n",
      "not_offensive       0.66      0.99      0.79      1175\n",
      "\n",
      "     accuracy                           0.66      1794\n",
      "    macro avg       0.67      0.51      0.43      1794\n",
      " weighted avg       0.67      0.66      0.54      1794\n",
      "\n",
      "korean\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4d015fd6254989a6332ae85133920c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba6250787594b11b754a3a9a0e0f711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive       0.69      0.45      0.54       697\n",
      "    offensive       0.66      0.84      0.74       903\n",
      "\n",
      "     accuracy                           0.67      1600\n",
      "    macro avg       0.68      0.65      0.64      1600\n",
      " weighted avg       0.67      0.67      0.66      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    print(lang)\n",
    "    models = [i for i in os.listdir('output') if lang in i and 'word' in i]\n",
    "    proc_data = pickle.load(open(f'processed_data/{lang}_processed.pkl','rb'))\n",
    "    preds = []\n",
    "    for m in tqdm(models):\n",
    "        loaded_model = joblib.load(f'output/{m}')\n",
    "        preds.append(loaded_model[0].predict_proba(proc_data['text_test']))\n",
    "        \n",
    "        \n",
    "    X_word = np.load(f'temp/embeds/{lang}/CtxtText_InputText_test.npy')[:,100:]\n",
    "    # X_char = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    char_text_data_list = []\n",
    "    _char_text_data = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    for text_vector in _char_text_data:\n",
    "        char_text_data_list.append(vector2matrix(text_vector))\n",
    "    char_text_data = np.asarray(char_text_data_list)\n",
    "    X_char = char_text_data\n",
    "\n",
    "#     preds = []\n",
    "\n",
    "    for cnn_model in tqdm([i for i in os.listdir('temp/models') if lang in i and 'word' in i]):\n",
    "        model = keras.models.load_model(f'temp/models/{cnn_model}')\n",
    "        if 'char' in cnn_model:\n",
    "            preds.append(model.predict(X_char,batch_size=128))\n",
    "        elif 'word' in cnn_model:\n",
    "            preds.append(model.predict(X_word,batch_size=128))\n",
    "        else:\n",
    "            preds.append(model.predict([X_word,X_char],batch_size=128))\n",
    "            \n",
    "    if lang=='filipino':\n",
    "        level = 4\n",
    "    else:\n",
    "        level = 4\n",
    "    ans = []\n",
    "    for i in range(len(preds[0])):\n",
    "        ts = []\n",
    "        for j in range(len(preds)):\n",
    "            ts = ts + list([preds[j][i].argmax()])\n",
    "        ans.append(1 if np.count_nonzero(ts)>=level else 0)\n",
    "    print(len(ts))\n",
    "    test_label_data = [i.tolist().index(1) for i in proc_data['label_test']]\n",
    "    print(classification_report(test_label_data, ans,target_names=list(proc_data['label_dict'].keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfbe31",
   "metadata": {},
   "source": [
    "# Char Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f978e72",
   "metadata": {},
   "source": [
    "## Maximize Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c70157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea7d4d935014d84b824e95f60b25c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91f676c75254c7da802302a9bebf698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.93      0.50      0.65      4124\n",
      "not_offensive       0.25      0.82      0.38       833\n",
      "\n",
      "     accuracy                           0.55      4957\n",
      "    macro avg       0.59      0.66      0.51      4957\n",
      " weighted avg       0.82      0.55      0.60      4957\n",
      "\n",
      "filipino\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566b939bf90a42cfae4984b2b8e2174a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469bdafbc58e41caa2830ef1cc439e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.77      0.78      0.77      2251\n",
      "not_offensive       0.81      0.80      0.80      2596\n",
      "\n",
      "     accuracy                           0.79      4847\n",
      "    macro avg       0.79      0.79      0.79      4847\n",
      " weighted avg       0.79      0.79      0.79      4847\n",
      "\n",
      "chinese\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711c83eacaa14a68a8d4e57e225d2755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781bea8e1f594c4abe568cf4ceb361cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.73      0.56      0.63       619\n",
      "not_offensive       0.79      0.89      0.84      1175\n",
      "\n",
      "     accuracy                           0.78      1794\n",
      "    macro avg       0.76      0.72      0.74      1794\n",
      " weighted avg       0.77      0.78      0.77      1794\n",
      "\n",
      "korean\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7dee90492743eaa19c9767fb9dc4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaf2670024f4090a5f34bc149e775ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive       0.76      0.44      0.55       697\n",
      "    offensive       0.67      0.89      0.77       903\n",
      "\n",
      "     accuracy                           0.69      1600\n",
      "    macro avg       0.71      0.66      0.66      1600\n",
      " weighted avg       0.71      0.69      0.67      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    print(lang)\n",
    "    models = [i for i in os.listdir('output') if lang in i and 'char' in i]\n",
    "    proc_data = pickle.load(open(f'processed_data/{lang}_processed.pkl','rb'))\n",
    "    preds = []\n",
    "    for m in tqdm(models):\n",
    "        loaded_model = joblib.load(f'output/{m}')\n",
    "        preds.append(loaded_model[0].predict_proba(proc_data['text_test']))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X_word = np.load(f'temp/embeds/{lang}/CtxtText_InputText_test.npy')[:,100:]\n",
    "    # X_char = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    char_text_data_list = []\n",
    "    _char_text_data = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    for text_vector in _char_text_data:\n",
    "        char_text_data_list.append(vector2matrix(text_vector))\n",
    "    char_text_data = np.asarray(char_text_data_list)\n",
    "    X_char = char_text_data\n",
    "\n",
    "#     preds = []\n",
    "\n",
    "    for cnn_model in tqdm([i for i in os.listdir('temp/models') if lang in i and 'char' in i]):\n",
    "        model = keras.models.load_model(f'temp/models/{cnn_model}')\n",
    "        if 'char' in cnn_model:\n",
    "            preds.append(model.predict(X_char,batch_size=128))\n",
    "        elif 'word' in cnn_model:\n",
    "            preds.append(model.predict(X_word,batch_size=128))\n",
    "        else:\n",
    "            preds.append(model.predict([X_word,X_char],batch_size=128))\n",
    "\n",
    "        \n",
    "    ans = []\n",
    "    for i in range(len(preds[0])):\n",
    "        ts = []\n",
    "        for j in range(len(preds)):\n",
    "            ts = ts + list(preds[j][i])\n",
    "        ans.append(ts.index(max(ts))%2)\n",
    "    test_label_data = [i.tolist().index(1) for i in proc_data['label_test']]\n",
    "    print(classification_report(test_label_data, ans,target_names=list(proc_data['label_dict'].keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d972a0",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ea8821",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b652a90471f444ab6c73b56678efdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c5813479aa4784b2d3d50cc8cc8a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.94      0.98      0.96      4124\n",
      "not_offensive       0.88      0.69      0.77       833\n",
      "\n",
      "     accuracy                           0.93      4957\n",
      "    macro avg       0.91      0.84      0.87      4957\n",
      " weighted avg       0.93      0.93      0.93      4957\n",
      "\n",
      "filipino\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6127f967fe4c3494ea8112684ab22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30d2c337027442890f0dbd5171cedb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.76      0.80      0.78      2251\n",
      "not_offensive       0.82      0.78      0.80      2596\n",
      "\n",
      "     accuracy                           0.79      4847\n",
      "    macro avg       0.79      0.79      0.79      4847\n",
      " weighted avg       0.79      0.79      0.79      4847\n",
      "\n",
      "chinese\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1a3c2f9f32457c82c5533d9b487956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594416ba41394cccba74adecb2ef0eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.87      0.36      0.51       619\n",
      "not_offensive       0.74      0.97      0.84      1175\n",
      "\n",
      "     accuracy                           0.76      1794\n",
      "    macro avg       0.81      0.67      0.68      1794\n",
      " weighted avg       0.79      0.76      0.73      1794\n",
      "\n",
      "korean\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a1fbdb63c04437a42c230940fe2f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b2c0b866064702bba839c107a618cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive       0.79      0.47      0.59       697\n",
      "    offensive       0.69      0.90      0.78       903\n",
      "\n",
      "     accuracy                           0.71      1600\n",
      "    macro avg       0.74      0.69      0.68      1600\n",
      " weighted avg       0.73      0.71      0.70      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    print(lang)\n",
    "    models = [i for i in os.listdir('output') if lang in i and 'char' in i]\n",
    "    proc_data = pickle.load(open(f'processed_data/{lang}_processed.pkl','rb'))\n",
    "    preds = []\n",
    "    for m in tqdm(models):\n",
    "        loaded_model = joblib.load(f'output/{m}')\n",
    "        preds.append(loaded_model[0].predict_proba(proc_data['text_test']))\n",
    "        \n",
    "        \n",
    "    X_word = np.load(f'temp/embeds/{lang}/CtxtText_InputText_test.npy')[:,100:]\n",
    "    # X_char = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    char_text_data_list = []\n",
    "    _char_text_data = np.load(f'temp/embeds/{lang}//Char_InputText_test.npy')\n",
    "    for text_vector in _char_text_data:\n",
    "        char_text_data_list.append(vector2matrix(text_vector))\n",
    "    char_text_data = np.asarray(char_text_data_list)\n",
    "    X_char = char_text_data\n",
    "\n",
    "\n",
    "    for cnn_model in tqdm([i for i in os.listdir('temp/models') if lang in i and 'char' in i]):\n",
    "        model = keras.models.load_model(f'temp/models/{cnn_model}')\n",
    "        if 'char' in cnn_model:\n",
    "            preds.append(model.predict(X_char,batch_size=128))\n",
    "        elif 'word' in cnn_model:\n",
    "            preds.append(model.predict(X_word,batch_size=128))\n",
    "        else:\n",
    "            preds.append(model.predict([X_word,X_char],batch_size=128))\n",
    "    if lang=='filipino':\n",
    "        level = 4\n",
    "    else:\n",
    "        level = 4\n",
    "    ans = []\n",
    "    for i in range(len(preds[0])):\n",
    "        ts = []\n",
    "        for j in range(len(preds)):\n",
    "            ts = ts + list([preds[j][i].argmax()])\n",
    "        ans.append(1 if np.count_nonzero(ts)>=level else 0)\n",
    "    print(len(ts))\n",
    "    test_label_data = [i.tolist().index(1) for i in proc_data['label_test']]\n",
    "    print(classification_report(test_label_data, ans,target_names=list(proc_data['label_dict'].keys())))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
