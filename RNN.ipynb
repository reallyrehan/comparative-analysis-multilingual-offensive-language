{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "Go7aY_3G0-ne",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Go7aY_3G0-ne",
    "outputId": "4ec6e7eb-f526-4fc8-d37f-6093398254b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordsegment in /usr/local/lib/python3.7/dist-packages (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "pip install wordsegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "pHFqYUFGacF-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHFqYUFGacF-",
    "outputId": "918db053-a147-41b1-df94-7a95b6bf29de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.62.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.6.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (3.12.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c04c40f6",
   "metadata": {
    "id": "c04c40f6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from hyperopt.pyll.base import scope \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import csv\n",
    "import sys\n",
    "from wordsegment import segment, load\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split, ConcatDataset, WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "50d24bc5",
   "metadata": {
    "id": "50d24bc5"
   },
   "outputs": [],
   "source": [
    "# ----------------- build labels and text ------------------\n",
    "def remove_empty(text, label):\n",
    "  indices = []\n",
    "  for i in range(len(text)):\n",
    "      if not text[i]:\n",
    "        indices.append(i)\n",
    "  if indices:\n",
    "    text = np.delete(text, indices).tolist()\n",
    "    label = np.delete(label, indices)\n",
    "  return text, label\n",
    "\n",
    "def concat_data(id2entities):\n",
    "    text_train = id2entities['text_train']\n",
    "    text_val = id2entities['text_test']\n",
    "    label_dict = id2entities['label_dict']\n",
    "    label_train = id2entities['label_train']\n",
    "    label_val = id2entities['label_test']\n",
    "    num_classes = len(label_dict)\n",
    "    label_train = np.nonzero(label_train)[1]\n",
    "    label_val = np.nonzero(label_val)[1]\n",
    "    text_train, label_train = remove_empty(text_train, label_train)\n",
    "    text_val, label_val = remove_empty(text_val, label_val)\n",
    "    return text_train, text_val, label_train, label_val, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "02e36253",
   "metadata": {
    "id": "02e36253"
   },
   "outputs": [],
   "source": [
    "# ----------------- pre-process text ------------------\n",
    "\n",
    "def text_preprocess(text, tknzr):\n",
    "    FLAGS = re.MULTILINE | re.DOTALL\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code is less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"#\\S+\", lambda hashtag: \" \".join(segment(hashtag.group()[1:]))) # segment hastags\n",
    "    tokens = tknzr.tokenize(text.lower())\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9d2e1261",
   "metadata": {
    "id": "9d2e1261"
   },
   "outputs": [],
   "source": [
    "# ----------------- build dictionary ------------------\n",
    "\n",
    "def build_dict(corp, mode):\n",
    "  wordcount = dict()\n",
    "  wordcount['<pad>'] = len(wordcount)\n",
    "\n",
    "  for ss in corp:   # for all sentences\n",
    "      if mode!= 'char':\n",
    "        words = ss.strip().lower().split()\n",
    "        for w in words:  # for all words in a sentence      \n",
    "          if w not in wordcount:\n",
    "              wordcount[w] = len(wordcount)\n",
    "      else:\n",
    "        for char in list(ss.strip().lower()):\n",
    "          if char not in wordcount:\n",
    "            wordcount[char] = len(wordcount)\n",
    "      \n",
    "  return(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "30e91049",
   "metadata": {
    "id": "30e91049"
   },
   "outputs": [],
   "source": [
    "# ----------------- convert text into list of index mapping using dictionary ------------------\n",
    "\n",
    "def grab_data(_text, dictionary, sentence_length, mode):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        _text (list(string)): list of comments\n",
    "        dictionary (dict): vocab in (word: frequency) format\n",
    "\n",
    "    Returns:\n",
    "        word_vectors (list(list(int))): list of sentences converted to list of word vectors\n",
    "    \"\"\"\n",
    "\n",
    "    sentences = []\n",
    "    sequence_length = []\n",
    "    for ss in _text:\n",
    "        if mode!= 'char':\n",
    "          words = ss.strip().lower().split()[:sentence_length]\n",
    "        else:\n",
    "          words = list(ss.strip().lower())[:sentence_length]\n",
    "        sentence = [dictionary[w] if w in dictionary else 1 for w in words]\n",
    "        sequence_length.append(len(sentence))\n",
    "        sentence += [0] * (sentence_length - len(sentence))\n",
    "        # words: is a list containing the words in the sentence.\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences, sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "318b587b",
   "metadata": {
    "id": "318b587b"
   },
   "outputs": [],
   "source": [
    "# ----------------- calculate weights for weighted sampler ----------------\n",
    "\n",
    "def make_weights_for_balanced_classes(nclasses):                        \n",
    "    count=Counter(nclasses)\n",
    "    class_count=np.array([count[i] for i in count])\n",
    "    weight=1./class_count\n",
    "    return weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "76474c7b",
   "metadata": {
    "id": "76474c7b"
   },
   "outputs": [],
   "source": [
    "# ----------------- generate weighted random sampler for stratified batches ----------------\n",
    "\n",
    "def generate_weighted_sampler(dataset):\n",
    "    weights = make_weights_for_balanced_classes(dataset.labels)\n",
    "    weights = torch.DoubleTensor(weights)\n",
    "    samples_weight = np.array([weights[t] for t in dataset.labels])\n",
    "    return WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "561b3434",
   "metadata": {
    "id": "561b3434"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- load and split data ----------------\n",
    "\n",
    "with open('train_path.txt') as f:\n",
    "    args = f.readline().strip().split()\n",
    "    train_path = args[0]\n",
    "    mode = args[2]\n",
    "    \n",
    "    \n",
    "data = pd.read_pickle(train_path)\n",
    "text_train, text_val, label_train, label_val, label_dict = concat_data(data)\n",
    "\n",
    "for i in range(len(text_train)):\n",
    "  if not text_train[i]:\n",
    "    print(i)\n",
    "\n",
    "word_dict = build_dict(text_train + text_val, mode)\n",
    "# padding_idx = len(word_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "TlbHOZXyIF_q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlbHOZXyIF_q",
    "outputId": "dc09f3d0-cc38-4f34-9865-270b637adb96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not_offensive': 0, 'offensive': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "Y-O9KXdZa5Ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-O9KXdZa5Ce",
    "outputId": "72005a78-764c-41d2-b147-bfaa516dbcfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Frequencies: \n",
      "[[    0 43080]\n",
      " [    1 25692]] \n",
      "\n",
      "Validation Label Frequencies: \n",
      "[[    0 10771]\n",
      " [    1  6423]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def freq_count(labels):\n",
    "  (unique, counts) = np.unique(labels, return_counts=True)\n",
    "  frequencies = np.asarray((unique, counts)).T\n",
    "  print(frequencies,\"\\n\")\n",
    "print(\"Train Label Frequencies: \")\n",
    "freq_count(label_train)\n",
    "print(\"Validation Label Frequencies: \")\n",
    "freq_count(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e2157485",
   "metadata": {
    "id": "e2157485"
   },
   "outputs": [],
   "source": [
    "# ----------------- Custom Dataset ----------------\n",
    "\n",
    "class AbusiveLanguageDetection(Dataset):\n",
    "    \"\"\"Abusive Language Detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, _text, _label, word_dict, sentence_length, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            _text (list(string)): list of comments\n",
    "            _label (integer): labels in range 0 - 2\n",
    "        \"\"\"\n",
    "        self.text, self.sequence_length = grab_data(_text, word_dict, sentence_length, mode)\n",
    "        self.labels = _label\n",
    "        self.length = len(self.text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.text[idx]), torch.tensor(self.labels[idx], dtype=torch.int64), self.sequence_length[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "622dde6c",
   "metadata": {
    "id": "622dde6c"
   },
   "outputs": [],
   "source": [
    "# ----------------- Prepare Data Loaders ----------------\n",
    "\n",
    "batch_size = 32\n",
    "sentence_length = 100\n",
    "train_dataset = AbusiveLanguageDetection(text_train, label_train, word_dict, sentence_length, mode)\n",
    "val_dataset = AbusiveLanguageDetection(text_val, label_val, word_dict, sentence_length, mode)\n",
    "train_sampler = generate_weighted_sampler(train_dataset)\n",
    "val_sampler = generate_weighted_sampler(val_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9d47224f",
   "metadata": {
    "id": "9d47224f"
   },
   "outputs": [],
   "source": [
    "# ----------------- Define Model ----------------\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, sentence_size, tagset_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first = True)\n",
    "        self.hidden2hidden = nn.Linear(hidden_dim, sentence_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden2tag = nn.Linear(sentence_size, tagset_size)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "\n",
    "    def forward(self, sentence, lengths):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        embeds = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, (hn, cn) = self.lstm(embeds)\n",
    "        classifier = self.hidden2hidden(hn[-1,:,:])\n",
    "        classifier = self.relu(self.dropout(classifier))\n",
    "        tag_scores = self.hidden2tag(classifier)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c00a1723",
   "metadata": {
    "id": "c00a1723"
   },
   "outputs": [],
   "source": [
    "# ----------------- Define Training ----------------\n",
    "\n",
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels, sequence_length in dataloader:\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images, sequence_length)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    for images, labels, sequence_length in dataloader:\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        output = model(images, sequence_length)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*images.size(0)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "mkAFGXh5VTIc",
   "metadata": {
    "id": "mkAFGXh5VTIc"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_dim = 300\n",
    "num_epochs = 10\n",
    "hidden_dim = 298\n",
    "learning_rate = 0.002\n",
    "vocab_size = len(word_dict)\n",
    "tagset_size = len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e5f3f59d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5f3f59d",
    "outputId": "bcef8c38-b255-44b2-9556-bc772e8406b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss has Decreased\n",
      "Epoch:1/10 AVG Training Loss:0.375 AVG Validation Loss:0.256 AVG Training Acc 83.77 % AVG Validation Acc 92.49 %\n",
      "Epoch:2/10 AVG Training Loss:0.270 AVG Validation Loss:0.287 AVG Training Acc 90.86 % AVG Validation Acc 92.78 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:3/10 AVG Training Loss:0.254 AVG Validation Loss:0.227 AVG Training Acc 91.63 % AVG Validation Acc 94.20 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:4/10 AVG Training Loss:0.247 AVG Validation Loss:0.200 AVG Training Acc 91.96 % AVG Validation Acc 94.64 %\n",
      "Epoch:5/10 AVG Training Loss:0.240 AVG Validation Loss:0.206 AVG Training Acc 92.23 % AVG Validation Acc 94.42 %\n",
      "Epoch:6/10 AVG Training Loss:0.236 AVG Validation Loss:0.212 AVG Training Acc 92.38 % AVG Validation Acc 94.50 %\n",
      "Epoch:7/10 AVG Training Loss:0.228 AVG Validation Loss:0.214 AVG Training Acc 92.66 % AVG Validation Acc 94.20 %\n",
      "Epoch:8/10 AVG Training Loss:0.230 AVG Validation Loss:0.260 AVG Training Acc 92.54 % AVG Validation Acc 92.72 %\n",
      "Epoch:9/10 AVG Training Loss:0.228 AVG Validation Loss:0.265 AVG Training Acc 92.62 % AVG Validation Acc 92.97 %\n",
      "Epoch:10/10 AVG Training Loss:0.227 AVG Validation Loss:0.215 AVG Training Acc 92.56 % AVG Validation Acc 94.20 %\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Train ----------------\n",
    "model = LSTM(embedding_dim, hidden_dim, vocab_size + 1, 200, tagset_size)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion_weight = torch.FloatTensor(make_weights_for_balanced_classes(train_dataset.labels)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[]}\n",
    "max_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "    val_loss, val_correct=valid_epoch(model,device,val_loader,criterion)\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "    val_loss = val_loss / len(val_loader.sampler)\n",
    "    val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "    if val_loss < max_val_loss:\n",
    "        max_val_loss = val_loss\n",
    "        print(\"Validation Loss has Decreased\")\n",
    "        torch.save(model,'LSTM.pt')\n",
    "\n",
    "    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                        num_epochs,\n",
    "                                                                                                        train_loss,\n",
    "                                                                                                        val_loss,\n",
    "                                                                                                        train_acc,\n",
    "                                                                                                        val_acc))\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "lYPJnPw_9Xgb",
   "metadata": {
    "id": "lYPJnPw_9Xgb"
   },
   "outputs": [],
   "source": [
    "# ----------------- Evaluate ----------------\n",
    "\n",
    "def evaluation(model, data_loader, label_dict):\n",
    "  pred_y = []\n",
    "  true_y = []\n",
    "  val_correct = 0\n",
    "  model.eval()\n",
    "  for images, labels, sequence_length in data_loader:\n",
    "    images,labels = images.to(device),labels.to(device)\n",
    "    output = F.log_softmax(model(images, sequence_length), dim=1)\n",
    "    scores, predictions = torch.max(output.data,1)\n",
    "    pred_y += predictions.tolist()\n",
    "    true_y += labels.tolist()\n",
    "    val_correct+=(predictions == labels).sum().item()\n",
    "  cm = confusion_matrix(true_y, pred_y)\n",
    "  print(classification_report(true_y, pred_y, target_names = label_dict.keys(), digits=5))\n",
    "  print(\"Confusion Matrix: \\n\", cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "QvKbSzhrR279",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QvKbSzhrR279",
    "outputId": "a019abf3-5f81-4156-a562-e623290a9ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive    0.95298   0.96657   0.95973     12624\n",
      "    offensive    0.90387   0.86827   0.88571      4570\n",
      "\n",
      "     accuracy                        0.94044     17194\n",
      "    macro avg    0.92843   0.91742   0.92272     17194\n",
      " weighted avg    0.93993   0.94044   0.94006     17194\n",
      "\n",
      "Confusion Matrix: \n",
      " [[12202   422]\n",
      " [  602  3968]]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('LSTM.pt')\n",
    "evaluation(model, val_loader, label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BpmDqVccOXQ3",
   "metadata": {
    "id": "BpmDqVccOXQ3"
   },
   "source": [
    "# BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5glT1DUrR7BV",
   "metadata": {
    "id": "5glT1DUrR7BV"
   },
   "outputs": [],
   "source": [
    "# ----------------- Define Model ----------------\n",
    "\n",
    "class BLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, sentence_size, tagset_size):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, batch_first = True, bidirectional = True)\n",
    "        self.hidden2hidden = nn.Linear(hidden_dim, sentence_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden2tag = nn.Linear(sentence_size, tagset_size)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "\n",
    "    def forward(self, sentence, lengths):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        embeds = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, (hn, cn) = self.lstm(embeds)\n",
    "        hn = self.dropout(hn)\n",
    "        classifier = self.hidden2hidden(torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1))\n",
    "        classifier = self.relu(self.dropout(classifier))\n",
    "        tag_scores = self.hidden2tag(classifier)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "Fd6zRMVeO4wY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "Fd6zRMVeO4wY",
    "outputId": "6eebf74f-0a22-4d25-cbd2-296f365bbe8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss has Decreased\n",
      "Epoch:1/10 AVG Training Loss:0.356 AVG Validation Loss:0.267 AVG Training Acc 85.95 % AVG Validation Acc 93.06 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:2/10 AVG Training Loss:0.299 AVG Validation Loss:0.262 AVG Training Acc 89.64 % AVG Validation Acc 92.25 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:3/10 AVG Training Loss:0.283 AVG Validation Loss:0.256 AVG Training Acc 90.36 % AVG Validation Acc 93.54 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:4/10 AVG Training Loss:0.283 AVG Validation Loss:0.254 AVG Training Acc 90.37 % AVG Validation Acc 93.22 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:5/10 AVG Training Loss:0.276 AVG Validation Loss:0.247 AVG Training Acc 90.61 % AVG Validation Acc 93.81 %\n",
      "Epoch:6/10 AVG Training Loss:0.276 AVG Validation Loss:0.279 AVG Training Acc 90.69 % AVG Validation Acc 92.85 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:7/10 AVG Training Loss:0.278 AVG Validation Loss:0.244 AVG Training Acc 90.65 % AVG Validation Acc 93.18 %\n",
      "Epoch:8/10 AVG Training Loss:0.276 AVG Validation Loss:0.262 AVG Training Acc 90.79 % AVG Validation Acc 93.03 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-9807bb0c256d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmax_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_correct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblstm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_correct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblstm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-202-44b433c6b8fe>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------------- Train ----------------\n",
    "\n",
    "embedding_dim = 300\n",
    "num_epochs = 10\n",
    "hidden_dim = 400\n",
    "learning_rate = 0.002\n",
    "vocab_size = len(word_dict)\n",
    "tagset_size = len(label_dict)\n",
    "blstm_model = BLSTM(embedding_dim, hidden_dim, vocab_size + 1, 200, tagset_size)\n",
    "blstm_model.to(device)\n",
    "optimizer = optim.Adam(blstm_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[]}\n",
    "max_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct=train_epoch(blstm_model,device,train_loader,criterion,optimizer)\n",
    "    val_loss, val_correct=valid_epoch(blstm_model,device,val_loader,criterion)\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "    val_loss = val_loss / len(val_loader.sampler)\n",
    "    val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "    if val_loss < max_val_loss:\n",
    "        max_val_loss = val_loss\n",
    "        print(\"Validation Loss has Decreased\")\n",
    "        torch.save(blstm_model,'BLSTM.pt')\n",
    "\n",
    "    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                        num_epochs,\n",
    "                                                                                                        train_loss,\n",
    "                                                                                                        val_loss,\n",
    "                                                                                                        train_acc,\n",
    "                                                                                                        val_acc))\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "JctvrzY0TLsT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "JctvrzY0TLsT",
    "outputId": "8dfd206b-8986-471f-cff1-cfb937119d57"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['val_loss'])\n",
    "plt.plot(history['train_loss'])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ks377rQRSVBq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ks377rQRSVBq",
    "outputId": "f91fd283-85ab-4cc6-94e7-9961b446ae6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive    0.94864   0.96373   0.95613     12765\n",
      "    offensive    0.89044   0.84963   0.86956      4429\n",
      "\n",
      "     accuracy                        0.93434     17194\n",
      "    macro avg    0.91954   0.90668   0.91284     17194\n",
      " weighted avg    0.93365   0.93434   0.93383     17194\n",
      "\n",
      "Confusion Matrix: \n",
      " [[12302   463]\n",
      " [  666  3763]]\n"
     ]
    }
   ],
   "source": [
    "blstm_model = torch.load('BLSTM.pt')\n",
    "evaluation(blstm_model, val_loader, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Xv-cuch-NnV",
   "metadata": {
    "id": "5Xv-cuch-NnV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classifier(5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
