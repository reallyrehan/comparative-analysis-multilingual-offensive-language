{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "Go7aY_3G0-ne",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Go7aY_3G0-ne",
    "outputId": "4ec6e7eb-f526-4fc8-d37f-6093398254b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordsegment in /usr/local/lib/python3.7/dist-packages (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "pip install wordsegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c04c40f6",
   "metadata": {
    "id": "c04c40f6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from hyperopt.pyll.base import scope \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import csv\n",
    "import sys\n",
    "from wordsegment import segment, load\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split, ConcatDataset, WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "50d24bc5",
   "metadata": {
    "id": "50d24bc5"
   },
   "outputs": [],
   "source": [
    "# ----------------- build labels and text ------------------\n",
    "def remove_empty(text, label):\n",
    "  indices = []\n",
    "  for i in range(len(text)):\n",
    "      if not text[i]:\n",
    "        indices.append(i)\n",
    "  if indices:\n",
    "    text = np.delete(text, indices).tolist()\n",
    "    label = np.delete(label, indices)\n",
    "  return text, label\n",
    "\n",
    "def concat_data(id2entities):\n",
    "    text_train = id2entities['text_train']\n",
    "    text_val = id2entities['text_test']\n",
    "    label_dict = id2entities['label_dict']\n",
    "    label_train = id2entities['label_train']\n",
    "    label_val = id2entities['label_test']\n",
    "    num_classes = len(label_dict)\n",
    "    label_train = np.nonzero(label_train)[1]\n",
    "    label_val = np.nonzero(label_val)[1]\n",
    "    text_train, label_train = remove_empty(text_train, label_train)\n",
    "    text_val, label_val = remove_empty(text_val, label_val)\n",
    "    return text_train, text_val, label_train, label_val, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "02e36253",
   "metadata": {
    "id": "02e36253"
   },
   "outputs": [],
   "source": [
    "# ----------------- pre-process text ------------------\n",
    "\n",
    "def text_preprocess(text, tknzr):\n",
    "    FLAGS = re.MULTILINE | re.DOTALL\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code is less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"#\\S+\", lambda hashtag: \" \".join(segment(hashtag.group()[1:]))) # segment hastags\n",
    "    tokens = tknzr.tokenize(text.lower())\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9d2e1261",
   "metadata": {
    "id": "9d2e1261"
   },
   "outputs": [],
   "source": [
    "# ----------------- build dictionary ------------------\n",
    "\n",
    "def build_dict(corp, mode):\n",
    "  wordcount = dict()\n",
    "  wordcount['<pad>'] = len(wordcount)\n",
    "\n",
    "  for ss in corp:   # for all sentences\n",
    "      if mode!= 'char':\n",
    "        words = ss.strip().lower().split()\n",
    "        for w in words:  # for all words in a sentence      \n",
    "          if w not in wordcount:\n",
    "              wordcount[w] = len(wordcount)\n",
    "      else:\n",
    "        for char in list(ss.strip().lower()):\n",
    "          if char not in wordcount:\n",
    "            wordcount[char] = len(wordcount)\n",
    "      \n",
    "  return(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "30e91049",
   "metadata": {
    "id": "30e91049"
   },
   "outputs": [],
   "source": [
    "# ----------------- convert text into list of index mapping using dictionary ------------------\n",
    "\n",
    "def grab_data(_text, dictionary, sentence_length, mode):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        _text (list(string)): list of comments\n",
    "        dictionary (dict): vocab in (word: frequency) format\n",
    "\n",
    "    Returns:\n",
    "        word_vectors (list(list(int))): list of sentences converted to list of word vectors\n",
    "    \"\"\"\n",
    "\n",
    "    sentences = []\n",
    "    sequence_length = []\n",
    "    for ss in _text:\n",
    "        if mode!= 'char':\n",
    "          words = ss.strip().lower().split()[:sentence_length]\n",
    "        else:\n",
    "          words = list(ss.strip().lower())[:sentence_length]\n",
    "        sentence = [dictionary[w] if w in dictionary else 1 for w in words]\n",
    "        sequence_length.append(len(sentence))\n",
    "        sentence += [0] * (sentence_length - len(sentence))\n",
    "        # words: is a list containing the words in the sentence.\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences, sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "318b587b",
   "metadata": {
    "id": "318b587b"
   },
   "outputs": [],
   "source": [
    "# ----------------- calculate weights for weighted sampler ----------------\n",
    "\n",
    "def make_weights_for_balanced_classes(nclasses):                        \n",
    "    count=Counter(nclasses)\n",
    "    class_count=np.array([count[i] for i in count])\n",
    "    weight=1./class_count\n",
    "    return weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "76474c7b",
   "metadata": {
    "id": "76474c7b"
   },
   "outputs": [],
   "source": [
    "# ----------------- generate weighted random sampler for stratified batches ----------------\n",
    "\n",
    "def generate_weighted_sampler(dataset):\n",
    "    weights = make_weights_for_balanced_classes(dataset.labels)\n",
    "    weights = torch.DoubleTensor(weights)\n",
    "    samples_weight = np.array([weights[t] for t in dataset.labels])\n",
    "    return WeightedRandomSampler(samples_weight, len(samples_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "561b3434",
   "metadata": {
    "id": "561b3434"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- load and split data ----------------\n",
    "\n",
    "with open('train_path.txt') as f:\n",
    "    args = f.readline().strip().split()\n",
    "    train_path = args[0]\n",
    "    mode = args[2]\n",
    "    \n",
    "    \n",
    "data = pd.read_pickle(train_path)\n",
    "text_train, text_val, label_train, label_val, label_dict = concat_data(data)\n",
    "\n",
    "for i in range(len(text_train)):\n",
    "  if not text_train[i]:\n",
    "    print(i)\n",
    "\n",
    "word_dict = build_dict(text_train + text_val, mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "TlbHOZXyIF_q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlbHOZXyIF_q",
    "outputId": "dc09f3d0-cc38-4f34-9865-270b637adb96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not_offensive': 0, 'offensive': 1}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "Y-O9KXdZa5Ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-O9KXdZa5Ce",
    "outputId": "72005a78-764c-41d2-b147-bfaa516dbcfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Frequencies: \n",
      "[[    0 43080]\n",
      " [    1 25692]] \n",
      "\n",
      "Validation Label Frequencies: \n",
      "[[    0 10771]\n",
      " [    1  6423]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def freq_count(labels):\n",
    "  (unique, counts) = np.unique(labels, return_counts=True)\n",
    "  frequencies = np.asarray((unique, counts)).T\n",
    "  print(frequencies,\"\\n\")\n",
    "print(\"Train Label Frequencies: \")\n",
    "freq_count(label_train)\n",
    "print(\"Validation Label Frequencies: \")\n",
    "freq_count(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e2157485",
   "metadata": {
    "id": "e2157485"
   },
   "outputs": [],
   "source": [
    "# ----------------- Custom Dataset ----------------\n",
    "\n",
    "class AbusiveLanguageDetection(Dataset):\n",
    "    \"\"\"Abusive Language Detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, _text, _label, word_dict, sentence_length, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            _text (list(string)): list of comments\n",
    "            _label (integer): labels in range 0 - 2\n",
    "        \"\"\"\n",
    "        self.text, self.sequence_length = grab_data(_text, word_dict, sentence_length, mode)\n",
    "        self.labels = _label\n",
    "        self.length = len(self.text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.text[idx]), torch.tensor(self.labels[idx], dtype=torch.int64), self.sequence_length[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "622dde6c",
   "metadata": {
    "id": "622dde6c"
   },
   "outputs": [],
   "source": [
    "# ----------------- Prepare Data Loaders ----------------\n",
    "\n",
    "batch_size = 32\n",
    "sentence_length = 100\n",
    "train_dataset = AbusiveLanguageDetection(text_train, label_train, word_dict, sentence_length, mode)\n",
    "val_dataset = AbusiveLanguageDetection(text_val, label_val, word_dict, sentence_length, mode)\n",
    "train_sampler = generate_weighted_sampler(train_dataset)\n",
    "val_sampler = generate_weighted_sampler(val_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9d47224f",
   "metadata": {
    "id": "9d47224f"
   },
   "outputs": [],
   "source": [
    "# ----------------- Define Model ----------------\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, sentence_size, tagset_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first = True)\n",
    "        self.hidden2hidden = nn.Linear(hidden_dim, sentence_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden2tag = nn.Linear(sentence_size, tagset_size)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "\n",
    "    def forward(self, sentence, lengths):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        embeds = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, (hn, cn) = self.lstm(embeds)\n",
    "        classifier = self.hidden2hidden(hn[-1,:,:])\n",
    "        classifier = self.relu(self.dropout(classifier))\n",
    "        tag_scores = self.hidden2tag(classifier)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c00a1723",
   "metadata": {
    "id": "c00a1723"
   },
   "outputs": [],
   "source": [
    "# ----------------- Define Training ----------------\n",
    "\n",
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels, sequence_length in dataloader:\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images, sequence_length)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    for images, labels, sequence_length in dataloader:\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "        output = model(images, sequence_length)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*images.size(0)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "mkAFGXh5VTIc",
   "metadata": {
    "id": "mkAFGXh5VTIc"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_dim = 300\n",
    "num_epochs = 10\n",
    "hidden_dim = 298\n",
    "learning_rate = 0.002\n",
    "vocab_size = len(word_dict)\n",
    "tagset_size = len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e5f3f59d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5f3f59d",
    "outputId": "bcef8c38-b255-44b2-9556-bc772e8406b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss has Decreased\n",
      "Epoch:1/10 AVG Training Loss:0.375 AVG Validation Loss:0.256 AVG Training Acc 83.77 % AVG Validation Acc 92.49 %\n",
      "Epoch:2/10 AVG Training Loss:0.270 AVG Validation Loss:0.287 AVG Training Acc 90.86 % AVG Validation Acc 92.78 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:3/10 AVG Training Loss:0.254 AVG Validation Loss:0.227 AVG Training Acc 91.63 % AVG Validation Acc 94.20 %\n",
      "Validation Loss has Decreased\n",
      "Epoch:4/10 AVG Training Loss:0.247 AVG Validation Loss:0.200 AVG Training Acc 91.96 % AVG Validation Acc 94.64 %\n",
      "Epoch:5/10 AVG Training Loss:0.240 AVG Validation Loss:0.206 AVG Training Acc 92.23 % AVG Validation Acc 94.42 %\n",
      "Epoch:6/10 AVG Training Loss:0.236 AVG Validation Loss:0.212 AVG Training Acc 92.38 % AVG Validation Acc 94.50 %\n",
      "Epoch:7/10 AVG Training Loss:0.228 AVG Validation Loss:0.214 AVG Training Acc 92.66 % AVG Validation Acc 94.20 %\n",
      "Epoch:8/10 AVG Training Loss:0.230 AVG Validation Loss:0.260 AVG Training Acc 92.54 % AVG Validation Acc 92.72 %\n",
      "Epoch:9/10 AVG Training Loss:0.228 AVG Validation Loss:0.265 AVG Training Acc 92.62 % AVG Validation Acc 92.97 %\n",
      "Epoch:10/10 AVG Training Loss:0.227 AVG Validation Loss:0.215 AVG Training Acc 92.56 % AVG Validation Acc 94.20 %\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Train ----------------\n",
    "model = LSTM(embedding_dim, hidden_dim, vocab_size + 1, 200, tagset_size)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion_weight = torch.FloatTensor(make_weights_for_balanced_classes(train_dataset.labels)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[]}\n",
    "max_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "    val_loss, val_correct=valid_epoch(model,device,val_loader,criterion)\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "    val_loss = val_loss / len(val_loader.sampler)\n",
    "    val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "    if val_loss < max_val_loss:\n",
    "        max_val_loss = val_loss\n",
    "        print(\"Validation Loss has Decreased\")\n",
    "        torch.save(model,'LSTM.pt')\n",
    "\n",
    "    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                        num_epochs,\n",
    "                                                                                                        train_loss,\n",
    "                                                                                                        val_loss,\n",
    "                                                                                                        train_acc,\n",
    "                                                                                                        val_acc))\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "lYPJnPw_9Xgb",
   "metadata": {
    "id": "lYPJnPw_9Xgb"
   },
   "outputs": [],
   "source": [
    "# ----------------- Evaluate ----------------\n",
    "\n",
    "def evaluation(model, data_loader, label_dict):\n",
    "  pred_y = []\n",
    "  true_y = []\n",
    "  val_correct = 0\n",
    "  model.eval()\n",
    "  for images, labels, sequence_length in data_loader:\n",
    "    images,labels = images.to(device),labels.to(device)\n",
    "    output = F.log_softmax(model(images, sequence_length), dim=1)\n",
    "    scores, predictions = torch.max(output.data,1)\n",
    "    pred_y += predictions.tolist()\n",
    "    true_y += labels.tolist()\n",
    "    val_correct+=(predictions == labels).sum().item()\n",
    "  cm = confusion_matrix(true_y, pred_y)\n",
    "  print(classification_report(true_y, pred_y, target_names = label_dict.keys(), digits=5))\n",
    "  print(\"Confusion Matrix: \\n\", cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "QvKbSzhrR279",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QvKbSzhrR279",
    "outputId": "a019abf3-5f81-4156-a562-e623290a9ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive    0.95298   0.96657   0.95973     12624\n",
      "    offensive    0.90387   0.86827   0.88571      4570\n",
      "\n",
      "     accuracy                        0.94044     17194\n",
      "    macro avg    0.92843   0.91742   0.92272     17194\n",
      " weighted avg    0.93993   0.94044   0.94006     17194\n",
      "\n",
      "Confusion Matrix: \n",
      " [[12202   422]\n",
      " [  602  3968]]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('LSTM.pt')\n",
    "evaluation(model, val_loader, label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BpmDqVccOXQ3",
   "metadata": {
    "id": "BpmDqVccOXQ3"
   },
   "source": [
    "# BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5glT1DUrR7BV",
   "metadata": {
    "id": "5glT1DUrR7BV"
   },
   "outputs": [],
   "source": [
    "# ----------------- Define Model ----------------\n",
    "\n",
    "class BLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, sentence_size, tagset_size):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, batch_first = True, bidirectional = True)\n",
    "        self.hidden2hidden = nn.Linear(hidden_dim, sentence_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden2tag = nn.Linear(sentence_size, tagset_size)\n",
    "        self.dropout = nn.Dropout(0.33)\n",
    "\n",
    "    def forward(self, sentence, lengths):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        embeds = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, (hn, cn) = self.lstm(embeds)\n",
    "        hn = self.dropout(hn)\n",
    "        classifier = self.hidden2hidden(torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1))\n",
    "        classifier = self.relu(self.dropout(classifier))\n",
    "        tag_scores = self.hidden2tag(classifier)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fd6zRMVeO4wY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "Fd6zRMVeO4wY",
    "outputId": "6eebf74f-0a22-4d25-cbd2-296f365bbe8f"
   },
   "outputs": [],
   "source": [
    "# ----------------- Train ----------------\n",
    "\n",
    "embedding_dim = 300\n",
    "num_epochs = 10\n",
    "hidden_dim = 400\n",
    "learning_rate = 0.002\n",
    "vocab_size = len(word_dict)\n",
    "tagset_size = len(label_dict)\n",
    "blstm_model = BLSTM(embedding_dim, hidden_dim, vocab_size + 1, 200, tagset_size)\n",
    "blstm_model.to(device)\n",
    "optimizer = optim.Adam(blstm_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[]}\n",
    "max_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct=train_epoch(blstm_model,device,train_loader,criterion,optimizer)\n",
    "    val_loss, val_correct=valid_epoch(blstm_model,device,val_loader,criterion)\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "    val_loss = val_loss / len(val_loader.sampler)\n",
    "    val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "    if val_loss < max_val_loss:\n",
    "        max_val_loss = val_loss\n",
    "        print(\"Validation Loss has Decreased\")\n",
    "        torch.save(blstm_model,'BLSTM.pt')\n",
    "\n",
    "    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                        num_epochs,\n",
    "                                                                                                        train_loss,\n",
    "                                                                                                        val_loss,\n",
    "                                                                                                        train_acc,\n",
    "                                                                                                        val_acc))\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "JctvrzY0TLsT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "JctvrzY0TLsT",
    "outputId": "8dfd206b-8986-471f-cff1-cfb937119d57"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['val_loss'])\n",
    "plt.plot(history['train_loss'])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ks377rQRSVBq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ks377rQRSVBq",
    "outputId": "f91fd283-85ab-4cc6-94e7-9961b446ae6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "not_offensive    0.94864   0.96373   0.95613     12765\n",
      "    offensive    0.89044   0.84963   0.86956      4429\n",
      "\n",
      "     accuracy                        0.93434     17194\n",
      "    macro avg    0.91954   0.90668   0.91284     17194\n",
      " weighted avg    0.93365   0.93434   0.93383     17194\n",
      "\n",
      "Confusion Matrix: \n",
      " [[12302   463]\n",
      " [  666  3763]]\n"
     ]
    }
   ],
   "source": [
    "blstm_model = torch.load('BLSTM.pt')\n",
    "evaluation(blstm_model, val_loader, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Xv-cuch-NnV",
   "metadata": {
    "id": "5Xv-cuch-NnV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classifier(5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
